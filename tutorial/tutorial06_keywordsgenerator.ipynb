{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KeywordsGenerator class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KeywordGenerator class extracts relevant keywords in the text data **based on a tf-idf score computed on the training dataset**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The input dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KeywordGenerator **requires a *tokens* column** fow which iach elements is a list of strings. The *tokens* column can be generated with a Tokenizer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "df_emails_preprocessed = pd.read_csv('./data/emails_preprocessed.csv', encoding='utf-8', sep=';')\n",
    "df_emails_preprocessed = df_emails_preprocessed[['tokens']]\n",
    "df_emails_preprocessed['tokens'] = df_emails_preprocessed['tokens'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['client',\n",
       " 'chez',\n",
       " 'pouvez',\n",
       " 'etablir',\n",
       " 'devis',\n",
       " 'fils',\n",
       " 'souhaite',\n",
       " 'louer',\n",
       " 'appartement',\n",
       " 'suivant',\n",
       " '25',\n",
       " 'rue',\n",
       " 'rueimaginaire',\n",
       " 'flag_cp_']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emails_preprocessed.tokens[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arguments "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specific parameters of the KeywordGenerator class are:\n",
    "- max_tfidf_features : size of vocabulary for tfidf\n",
    "- keywords : list of keyword to be extracted in priority (this list can be defined in the conf file)\n",
    "- stopwords : list of keywords to be ignored (this list can be defined in the conf file)\n",
    "- resample : when DataFrame contains a ‘label’ column, balance the dataset by resampling\n",
    "- n_max_keywords : maximum number of keywords to be returned for each email\n",
    "- n_min_keywords : minimum number of keywords to be returned for each email\n",
    "- threshold_keywords : minimum tf-idf score for a word to be selected as keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['devis', 'contrat', 'resilitation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [\"au\", \"aux\", \"avec\", \"ce\", \"ces\", \"dans\", \"de\", \"des\", \"du\",\n",
    "        \"elle\", \"en\", \"et\", \"eux\", \"il\", \"je\", \"la\", \"le\", \"leur\", \"lui\", \"ma\",\n",
    "        \"mais\", \"me\", \"même\", \"mes\", \"moi\", \"mon\", \"ne\", \"nos\", \"notre\", \"nous\",\n",
    "        \"on\", \"ou\",\"par\", \"pas\", \"pour\", \"qu\", \"que\", \"qui\", \"sa\", \"se\", \"ses\",\n",
    "        \"son\", \"sur\",\"ta\", \"te\", \"tes\", \"toi\", \"ton\", \"tu\", \"un\", \"une\", \"vos\",\n",
    "        \"votre\", \"vous\", \"c\", \"d\", \"j\", \"l\", \"à\", \"m\", \"n\", \"s\", \"t\", \"y\", \"été\",\n",
    "        \"étée\", \"étées\", \"étés\", \"étant\", \"étante\", \"étants\", \"étantes\", \"suis\",\n",
    "        \"es\", \"est\", \"sommes\", \"êtes\", \"sont\", \"serai\", \"seras\", \"sera\", \"serons\",\n",
    "        \"serez\", \"seront\", \"serais\", \"serait\", \"serions\", \"seriez\", \"seraient\",\n",
    "        \"étais\", \"était\", \"étions\", \"étiez\", \"étaient\", \"fus\", \"fut\", \"fûmes\",\n",
    "        \"fûtes\", \"furent\", \"sois\", \"soit\", \"soyons\", \"soyez\", \"soient\", \"fusse\",\n",
    "        \"fusses\", \"fût\", \"fussions\", \"fussiez\", \"fussent\", \"ayant\", \"ayante\",\n",
    "        \"ayantes\", \"ayants\", \"eu\", \"eue\", \"eues\", \"eus\", \"ai\", \"as\", \"avons\",\n",
    "        \"avez\", \"ont\", \"aurai\", \"auras\", \"aura\", \"aurons\", \"aurez\", \"auront\",\n",
    "        \"aurais\", \"aurait\", \"aurions\", \"auriez\", \"auraient\", \"avais\", \"avait\",\n",
    "        \"avions\", \"aviez\", \"avaient\", \"eut\", \"eûmes\", \"eûtes\", \"eurent\", \"aie\",\n",
    "        \"aies\", \"ait\", \"ayons\", \"ayez\", \"aient\", \"eusse\", \"eusses\", \"eût\",\n",
    "        \"eussions\", \"eussiez\", \"eussent\", \"suivant\"],"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the KeywordsGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from melusine.summarizer.keywords_generator import KeywordsGenerator\n",
    "\n",
    "keywords_generator = KeywordsGenerator(keywords = keywords,\n",
    "                                       stopwords = stopwords,\n",
    "                                       n_max_keywords=5,\n",
    "                                       n_min_keywords=0,\n",
    "                                       threshold_keywords=0.1,\n",
    "                                       keywords_coef=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the KeywordsGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/florianarthur/opt/anaconda3/envs/melusine_new/lib/python3.8/site-packages/sklearn/base.py:209: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  warnings.warn('From version 0.24, get_params will raise an '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KeywordsGenerator(keywords=['devis', 'contrat', 'resilitation'],\n",
       "                  max_tfidf_features=None, n_max_keywords=5,\n",
       "                  stopwords=(['au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de',\n",
       "                              'des', 'du', 'elle', 'en', 'et', 'eux', 'il',\n",
       "                              'je', 'la', 'le', 'leur', 'lui', 'ma', 'mais',\n",
       "                              'me', 'même', 'mes', 'moi', 'mon', 'ne', 'nos',\n",
       "                              'notre', 'nous', ...],),\n",
       "                  threshold_keywords=0.1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_generator.fit(df_emails_preprocessed) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emails_preprocessed = keywords_generator.transform(df_emails_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[client, chez, pouvez, etablir, devis, fils, s...</td>\n",
       "      <td>[pouvez, devis, fils, suivant, flag_cp_]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[informe, nouvelle, immatriculation, enfin, fa...</td>\n",
       "      <td>[nouvelle, immatriculation, prie, trouver, faire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[suite, a, conversation, telephonique, mardi, ...</td>\n",
       "      <td>[conversation, mardi, pourriez, dire, afin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[fais, suite, a, mail, envoye, bulletin, salai...</td>\n",
       "      <td>[suite, mail, bulletin, salaire, trouverez]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[voici, ci, joint, bulletin, salaire, comme, d...</td>\n",
       "      <td>[ci, joint, bulletin, salaire, comme]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [client, chez, pouvez, etablir, devis, fils, s...   \n",
       "1  [informe, nouvelle, immatriculation, enfin, fa...   \n",
       "2  [suite, a, conversation, telephonique, mardi, ...   \n",
       "3  [fais, suite, a, mail, envoye, bulletin, salai...   \n",
       "4  [voici, ci, joint, bulletin, salaire, comme, d...   \n",
       "\n",
       "                                            keywords  \n",
       "0           [pouvez, devis, fils, suivant, flag_cp_]  \n",
       "1  [nouvelle, immatriculation, prie, trouver, faire]  \n",
       "2        [conversation, mardi, pourriez, dire, afin]  \n",
       "3        [suite, mail, bulletin, salaire, trouverez]  \n",
       "4              [ci, joint, bulletin, salaire, comme]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emails_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['informe',\n",
       " 'nouvelle',\n",
       " 'immatriculation',\n",
       " 'enfin',\n",
       " 'faite',\n",
       " 'prie',\n",
       " 'trouver',\n",
       " 'donc',\n",
       " 'carte',\n",
       " 'grise',\n",
       " 'ainsi',\n",
       " 'nouvelle',\n",
       " 'immatriculation',\n",
       " 'demanderai',\n",
       " 'faire',\n",
       " 'les',\n",
       " 'changements',\n",
       " 'necessaires',\n",
       " 'concernant',\n",
       " 'assurance']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emails_preprocessed.tokens[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nouvelle', 'immatriculation', 'prie', 'trouver', 'faire']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emails_preprocessed.keywords[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "melusine_new\n",
   "language": "python",
   "name": "melusine_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
