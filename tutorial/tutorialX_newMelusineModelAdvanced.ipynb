{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcf8701a-23b8-4c46-a3e3-b43bb11fc547",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dd5501-be02-4fd8-909d-a111feccd594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from melusine.nlp_tools.embedding import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a253e314-05f0-4f60-8aac-2db6696527a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from melusine.models.models_v2.transformers_model import TransformerMelusineModel\n",
    "from melusine.models.models_v2.cnn_model import CnnMelusineModel\n",
    "from melusine.models.models_v2.transformers_model import TransformerMelusineModel\n",
    "from melusine.models.models_v2.trainer import MelusineTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9449df-0f61-4364-a28f-3c11317a4e40",
   "metadata": {},
   "source": [
    "# Setup logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b355c3f4-ac54-4645-a5f3-16819fd5bf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger(\"gensim\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbae4caf-144a-4259-917c-48b4c9232b1a",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab3071f-e252-41b0-a68f-ad358f5b9064",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emails_clean = pd.read_csv('../tutorial/data/emails_preprocessed.csv', encoding='utf-8', sep=';')\n",
    "# Artificially increase df size by duplication\n",
    "df_emails_clean = pd.concat([df_emails_clean] * 100, ignore_index=True) \n",
    "df_emails_clean['clean_body'] = df_emails_clean['clean_body'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763fe684-9e53-4398-9797-b8bc2495b33c",
   "metadata": {},
   "source": [
    "# Metadata preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd1996d-e6ad-4b32-90d5-2656c830597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from melusine.prepare_email.metadata_engineering import MetaExtension\n",
    "from melusine.prepare_email.metadata_engineering import MetaDate\n",
    "from melusine.prepare_email.metadata_engineering import MetaAttachmentType\n",
    "from melusine.prepare_email.metadata_engineering import Dummifier\n",
    "\n",
    "# Pipeline to extract dummified metadata\n",
    "MetadataPipeline = Pipeline([\n",
    "    ('MetaExtension', MetaExtension()),\n",
    "    ('MetaDate', MetaDate()),\n",
    "    ('MetaAttachmentType',MetaAttachmentType()),\n",
    "    ('Dummifier', Dummifier())\n",
    "])\n",
    "df_meta = MetadataPipeline.fit_transform(df_emails_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da203a42-7671-46a6-9c1b-1f7d440ffaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([df_emails_clean['clean_body'],df_meta],axis=1)\n",
    "y = df_emails_clean['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e993a00-81e6-4c0a-a84c-900a3ca9e417",
   "metadata": {},
   "source": [
    "# Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cb0050-38f8-455c-a073-e8b4aedc20ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from melusine.nlp_tools.tokenizer import WordLevelTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2587f71-25fa-483f-bfac-eaac54809a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WordLevelTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be101ede-07cd-4948-bd6a-9092a260ba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emails_clean['tokens'] = df_emails_clean['clean_body'].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5d99c1-40f3-4c6f-afc2-874fbeaaae44",
   "metadata": {},
   "source": [
    "# Train word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a06419c-7fbf-45fd-b7ec-61acbe97be7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "vector_size = 50\n",
    "min_count = 2\n",
    "epochs = 2\n",
    "\n",
    "embedding = Word2Vec(\n",
    "    size=vector_size,\n",
    "    min_count=min_count,\n",
    ")\n",
    "\n",
    "\n",
    "embedding.build_vocab(df_emails_clean['tokens'])\n",
    "embedding.train(\n",
    "    df_emails_clean['tokens'],\n",
    "    total_examples=embedding.corpus_count,\n",
    "    epochs=epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70e7be6-325d-4566-8b68-ffdab7189798",
   "metadata": {},
   "source": [
    "# Classification using a CnnMelusineModel and a custom network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbecea6-a427-4103-b1bf-7da32acaa9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fafb7c-325b-4095-ba4f-9b81808bdc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom CNN architecture\n",
    "def custom_cnn_archi(input_net):\n",
    "    cnn_net = Conv1D(200, 2, padding=\"same\", activation=\"linear\", strides=1)(input_net)\n",
    "    cnn_net = SpatialDropout1D(0.15)(cnn_net)\n",
    "    cnn_net = BatchNormalization()(cnn_net)\n",
    "    cnn_net = LeakyReLU(alpha=0.05)(cnn_net)\n",
    "    cnn_net = GlobalMaxPooling1D()(cnn_net)\n",
    "\n",
    "    return cnn_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86473c7b-25ec-4791-a991-8aef75135835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom meta architecture\n",
    "def custom_meta_archi(nb_meta):\n",
    "    meta_input = Input(shape=(nb_meta,), dtype=\"float32\")\n",
    "\n",
    "    meta_net = Dense(150, activation=\"linear\")(meta_input)\n",
    "    meta_net = Dropout(0.2)(meta_net)\n",
    "    meta_net = LeakyReLU(alpha=0.05)(meta_net)\n",
    "\n",
    "    return meta_input, meta_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bde2aa-741f-4a09-8e04-b2c6168da402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dense architecture\n",
    "def custom_dense_archi(input_net):\n",
    "    dense_net = Dense(200, activation=\"linear\")(input_net)\n",
    "    dense_net = Dropout(0.2)(dense_net)\n",
    "    dense_net = LeakyReLU(alpha=0.05)(dense_net)\n",
    "\n",
    "    return dense_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcbe79d-b483-4316-9828-73ac0d156ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a output layer\n",
    "def custom_output_layer(input_net, n_targets):\n",
    "    output = Dense(n_targets, activation=\"linear\")(input_net)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce98acc-1132-43da-bc95-ec61f4cc0076",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CnnMelusineModel(  \n",
    "    tokenizer=tokenizer,\n",
    "    text_column=\"clean_body\",\n",
    "    seq_max=128,\n",
    "    pretrained_embedding=embedding.wv,\n",
    "    meta_input_list=['extension', 'dayofweek','hour', 'min', 'attachment_type'],\n",
    "    cnn_archi=custom_cnn_archi,\n",
    "    meta_archi=custom_meta_archi,\n",
    "    dense_archi=custom_dense_archi,\n",
    "    output_archi=custom_output_layer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e31cf9-b20c-4522-99ff-f8e314058c9f",
   "metadata": {},
   "source": [
    "# Melusine Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48e8fdf-0a79-4be1-971d-de73a98e6465",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MelusineTrainer(model, epochs=2, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a575b7d-7603-42c9-89f1-7e550f459dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455fe8fe-11eb-40dc-ae70-378268446e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec620d2-8b49-4a5a-abda-f782db251358",
   "metadata": {},
   "source": [
    "# Classification using a custom MelusineModel class\n",
    "\n",
    "The methodology presented above makes the CnnMelusineModel very flexible in terms of architecture.  \n",
    "If this enough for you, MelusineModel classes are designed to be easily customized by inheritance.  \n",
    "\n",
    "You just need to define a custom class that inherits from a MelusineModel class \n",
    "(BaseMelusineModel, CnnMelusineModel or TransformersMelusineModel).  \n",
    "Then you can override :  \n",
    "* the create_network method to define a custom network\n",
    "* the fit method to define a custom data preparztion methodology\n",
    "\n",
    "In the exemple below, a custom class is defined to implement an RNN model.  \n",
    "The class is then simply fed to the MelusineTrainer for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9161f07d-8d8f-4b3f-93c9-b4d49e3d12fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "class MyCustomMelusineModel(CnnMelusineModel):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        text_column,\n",
    "        tokenizer,\n",
    "        seq_max,\n",
    "        pretrained_embedding,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \n",
    "        super().__init__(\n",
    "            text_column=text_column,\n",
    "            tokenizer=tokenizer,\n",
    "            seq_max=seq_max,\n",
    "            pretrained_embedding=pretrained_embedding,\n",
    "            **kwargs\n",
    "        )\n",
    "    \n",
    "    def create_network(self) -> None:\n",
    "        \"\"\"\n",
    "        Create the neural network using Keras.\n",
    "        \"\"\"\n",
    "        inputs = list()\n",
    "\n",
    "        # Text input\n",
    "        text_input = Input(shape=(self.seq_max,), dtype=\"int32\")\n",
    "        inputs.append(text_input)\n",
    "\n",
    "        # Embedding layer\n",
    "        embedding_net = self.pretrained_embedding.get_keras_embedding(\n",
    "            train_embeddings=self.trainable\n",
    "        )(text_input)\n",
    "        \n",
    "        # RNN layer\n",
    "        x = Bidirectional(GRU(80, return_sequences=True))(embedding_net)\n",
    "        x = SpatialDropout1D(0.15)(x)\n",
    "        x = Bidirectional(GRU(40, return_sequences=True))(x)\n",
    "        x = SpatialDropout1D(0.15)(x)\n",
    "        x = GlobalMaxPooling1D()(x)\n",
    "        x = Dense(250, activation=\"linear\")(x)\n",
    "        x = LeakyReLU(alpha=0.05)(x)\n",
    "        x = Dense(150, activation=\"linear\")(x)\n",
    "        x = Dropout(0.15)(x)\n",
    "        x = LeakyReLU(alpha=0.05)(x)\n",
    "        \n",
    "        # Output layer\n",
    "        output = Dense(self.n_targets, activation=\"softmax\")(x)\n",
    "                                                        \n",
    "        # Build model\n",
    "        model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "        self.model = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ecb7f7-00cb-4b3c-a25d-1d19c974c87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyCustomMelusineModel(  \n",
    "    tokenizer=tokenizer,\n",
    "    text_column=\"clean_body\",\n",
    "    seq_max=128,\n",
    "    pretrained_embedding=embedding.wv,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8177d6-8004-41dc-8e30-19d44c81ed08",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MelusineTrainer(model, epochs=2, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa217eec-1f17-441b-86cb-5e7107395671",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb401d7f-d273-498b-be49-1fdbb5fa2821",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "melusine_perso38",
   "language": "python",
   "name": "melusine_perso38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
