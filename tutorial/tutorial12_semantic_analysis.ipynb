{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Semantic Analysis tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **SemanticDetector** class is used to predict a sentiment score in a document / email.\n",
    "\n",
    "For that purpose, two inputs are required:\n",
    "- a list of seed words that caracterize a sentiment \n",
    "  Exemple : the seed words [\"mad\", \"furious\", \"insane\"] caracterize the sentiment \"dissatisfaction\"\n",
    "- a trained embedding (Melusine **Embedding** class instance) to compute distances between words/tokens\n",
    "\n",
    "The three steps for sentiment score prediction are the following:\n",
    "- Instanciate a SentimentDetector object with a list of seed words as argument\n",
    "- Use the SentimentDetector.fit method (with an embedding object as argument) to compute the lexicons\n",
    "- Use the SentimentDetector.predict method on a document/email DataFrame to predict the sentiment score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal working exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:50:13.313877Z",
     "start_time": "2021-05-27T13:50:09.819746Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# NLP tools\n",
    "from melusine.nlp_tools.embedding import Word2VecTrainer\n",
    "from melusine.nlp_tools.tokenizer import WordLevelTokenizer\n",
    "\n",
    "# Models\n",
    "from melusine.models.modeler_semantic import SemanticDetector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load email data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:50:13.330379Z",
     "start_time": "2021-05-27T13:50:13.316896Z"
    }
   },
   "outputs": [],
   "source": [
    "from melusine import load_email_data\n",
    "df_emails_clean = load_email_data(type=\"preprocessed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the trainer\n",
    "embedding_trainer = Word2VecTrainer(\n",
    "    input_column='clean_body',\n",
    "    workers=1,\n",
    "    min_count=2\n",
    ")\n",
    "\n",
    "# Train the word embeddings model\n",
    "embedding_trainer.train(df_emails_clean)\n",
    "\n",
    "embedding = embedding_trainer.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:50:13.545992Z",
     "start_time": "2021-05-27T13:50:13.525717Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'vehicule', 'suite']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a list of words present in the Embedding vocabulary\n",
    "list(embedding.key_to_index.keys())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:50:13.567162Z",
     "start_time": "2021-05-27T13:50:13.553199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ecrit', 0.2420215755701065),\n",
       " ('joins', 0.23045018315315247),\n",
       " ('flag_mail_', 0.21315081417560577)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the trained embedding : print most similar words\n",
    "embedding.most_similar('client', topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:50:13.647785Z",
     "start_time": "2021-05-27T13:50:13.588807Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize the text in the clean_body column\n",
    "tokenizer = WordLevelTokenizer()\n",
    "df_emails_clean[\"tokens\"] = df_emails_clean[\"clean_body\"].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:50:13.661994Z",
     "start_time": "2021-05-27T13:50:13.652937Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [client, chez, pouvez, etablir, devis, fils, s...\n",
       "1    [informe, nouvelle, immatriculation, enfin, fa...\n",
       "2    [suite, a, conversation, telephonique, flag_da...\n",
       "3    [fais, suite, a, mail, envoye, bulletin, salai...\n",
       "4    [voici, ci, joint, bulletin, salaire, comme, d...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the tokenizer : print tokens\n",
    "df_emails_clean['tokens'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciate and fit the Sentiment Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:50:13.676559Z",
     "start_time": "2021-05-27T13:50:13.665509Z"
    }
   },
   "outputs": [],
   "source": [
    "seed_word_list = ['immatriculation']\n",
    "\n",
    "# Instanciate a SentimentDetector object\n",
    "semantic_detector = SemanticDetector(base_seed_words=seed_word_list, tokens_column='tokens')\n",
    "\n",
    "# Fit the SentimentDetector using the trained embedding\n",
    "semantic_detector.fit(embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:50:13.689349Z",
     "start_time": "2021-05-27T13:50:13.678720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of seed words:\n",
      "['immatriculation']\n"
     ]
    }
   ],
   "source": [
    "print('List of seed words:')\n",
    "print(semantic_detector.seed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:50:13.700084Z",
     "start_time": "2021-05-27T13:50:13.695203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Part of) Lexicon associated with the seed words \"immatriculation\":\n",
      "  00 : 0.032913681119680405\n",
      "  1 : -0.06338156759738922\n",
      "  2 : -0.01811196282505989\n",
      "  a : 0.026584366336464882\n",
      "  adresse : -0.042879264801740646\n",
      "  afin : -0.0378701388835907\n",
      "  ainsi : -0.1225186288356781\n",
      "  assurance : -0.08176179230213165\n",
      "  assurer : -0.05094974860548973\n",
      "  attached : 0.09211645275354385\n"
     ]
    }
   ],
   "source": [
    "seed_word = semantic_detector.seed_list[0]\n",
    "lexicon = semantic_detector.lexicon\n",
    "sorted_lexicon = dict(sorted(lexicon.items(), key = lambda x: x[0]))\n",
    "\n",
    "print(f'(Part of) Lexicon associated with the seed words \"{\", \".join(semantic_detector.seed_list)}\":')\n",
    "for word, sentiment_score in list(sorted_lexicon.items())[:10]:\n",
    "    print('  ' + word + ' : ' + str(sentiment_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict and print the sentiment score\n",
    "\n",
    "**Warning :** In this exemple, the embedding is trained on a corpus of 40 emails which is WAY too small to yield valuable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:50:13.739872Z",
     "start_time": "2021-05-27T13:50:13.702935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>header</th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>attachment</th>\n",
       "      <th>sexe</th>\n",
       "      <th>age</th>\n",
       "      <th>label</th>\n",
       "      <th>is_begin_by_transfer</th>\n",
       "      <th>is_answer</th>\n",
       "      <th>is_transfer</th>\n",
       "      <th>structured_historic</th>\n",
       "      <th>structured_body</th>\n",
       "      <th>last_body</th>\n",
       "      <th>clean_body</th>\n",
       "      <th>clean_header</th>\n",
       "      <th>tokens</th>\n",
       "      <th>semantic_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>\\n  \\n  \\n  \\n  \\n  \\n Madame, Monsieur, \\n  ...</td>\n",
       "      <td>déclarations de sinistre corporel et matériel</td>\n",
       "      <td>mardi 5 juin 2018 16 h 06 CEST</td>\n",
       "      <td>Monsieur Dupont &lt;monsieurdupont@extensionb.com&gt;</td>\n",
       "      <td>demandes@societeimaginaire.fr</td>\n",
       "      <td>[\"doc.pdf\"]</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>habitation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': ' \\n  \\n  \\n  \\n  \\n  \\n Madame, Mon...</td>\n",
       "      <td>[{'meta': {'date': None, 'from': None, 'to': N...</td>\n",
       "      <td>Je vous prie de trouver ci-joint une déclar...</td>\n",
       "      <td>je vous prie de trouver ci-joint une declarati...</td>\n",
       "      <td>declarations de sinistre corporel et materiel</td>\n",
       "      <td>[prie, trouver, ci-joint, declaration, sinistr...</td>\n",
       "      <td>0.126272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\\n  \\n  \\n  \\n Bonjour, \\n  \\n Pourriez vous ...</td>\n",
       "      <td>Fwd: Changement de vehicule</td>\n",
       "      <td>02/06/2018 11:07</td>\n",
       "      <td>monsieurdupont@extensionf.net</td>\n",
       "      <td>Societe Imaginaire &lt;region@Societeimaginaire.fr&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>M</td>\n",
       "      <td>64</td>\n",
       "      <td>vehicule</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[{'text': ' \\n  \\n  \\n  \\n Bonjour, \\n  \\n Pou...</td>\n",
       "      <td>[{'meta': {'date': None, 'from': None, 'to': N...</td>\n",
       "      <td>Pourriez vous faire suite au mail suivant en ...</td>\n",
       "      <td>pourriez vous faire suite au mail suivant en d...</td>\n",
       "      <td>changement de vehicule</td>\n",
       "      <td>[pourriez, faire, suite, mail, suivant, date, ...</td>\n",
       "      <td>0.122522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\\n  \\n  \\n  \\n Bonjour Monsieur, \\n Pouvez-vo...</td>\n",
       "      <td>Re: Demande</td>\n",
       "      <td>30/05/2018 10:12</td>\n",
       "      <td>Dupont &lt;monsieurdupont@extensiona.com&gt;</td>\n",
       "      <td>conseiller@Societeimaginaire.fr</td>\n",
       "      <td>[]</td>\n",
       "      <td>F</td>\n",
       "      <td>63</td>\n",
       "      <td>bilan</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': \" \\n  \\n  \\n  \\n Bonjour Monsieur, \\...</td>\n",
       "      <td>[{'meta': {'date': None, 'from': None, 'to': N...</td>\n",
       "      <td>Pouvez-vous m'appeler lundi prochain en fin d'...</td>\n",
       "      <td>pouvez-vous m'appeler lundi prochain en fin d'...</td>\n",
       "      <td>demande</td>\n",
       "      <td>[pouvez-vous, appeler, flag_date_, prochain, f...</td>\n",
       "      <td>0.122522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n Bonjour Ma...</td>\n",
       "      <td>demande attestation - Envoi d'un document de l...</td>\n",
       "      <td>lundi 4 juin 2018 10 h 22 CEST</td>\n",
       "      <td>Monsieur Dupont &lt;monsieurdupont@extensionc.com&gt;</td>\n",
       "      <td>demandes@societeimaginaire.fr</td>\n",
       "      <td>[]</td>\n",
       "      <td>F</td>\n",
       "      <td>88</td>\n",
       "      <td>resiliation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': \" \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n...</td>\n",
       "      <td>[{'meta': {'date': None, 'from': None, 'to': N...</td>\n",
       "      <td>Je vous remercie pour l'attestation demandée ...</td>\n",
       "      <td>je vous remercie pour l'attestation demandee p...</td>\n",
       "      <td>demande attestation envoi d'un document de la ...</td>\n",
       "      <td>[remercie, attestation, demandee, telephone, r...</td>\n",
       "      <td>0.102057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\\n  \\n  \\n  \\n Numéro Tél. : 0600000000 \\n E-...</td>\n",
       "      <td>Réclamations</td>\n",
       "      <td>03/06/2018 16:52</td>\n",
       "      <td>monsieurdupont@extensiona.com</td>\n",
       "      <td>conseiller@Societeimaginaire.fr</td>\n",
       "      <td>[]</td>\n",
       "      <td>F</td>\n",
       "      <td>20</td>\n",
       "      <td>habitation</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': \" \\n  \\n  \\n  \\n Numéro Tél. : 06000...</td>\n",
       "      <td>[{'meta': {'date': None, 'from': None, 'to': N...</td>\n",
       "      <td>Numéro Tél. : 0600000000 E-mail : monsieurd...</td>\n",
       "      <td>numero tel. : 0600000000 e-mail : monsieurdupo...</td>\n",
       "      <td>reclamations</td>\n",
       "      <td>[numero, tel, flag_phone_, e-mail, flag_mail_,...</td>\n",
       "      <td>0.100749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 body  \\\n",
       "33   \\n  \\n  \\n  \\n  \\n  \\n Madame, Monsieur, \\n  ...   \n",
       "21   \\n  \\n  \\n  \\n Bonjour, \\n  \\n Pourriez vous ...   \n",
       "10   \\n  \\n  \\n  \\n Bonjour Monsieur, \\n Pouvez-vo...   \n",
       "15   \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n Bonjour Ma...   \n",
       "22   \\n  \\n  \\n  \\n Numéro Tél. : 0600000000 \\n E-...   \n",
       "\n",
       "                                               header  \\\n",
       "33      déclarations de sinistre corporel et matériel   \n",
       "21                        Fwd: Changement de vehicule   \n",
       "10                                        Re: Demande   \n",
       "15  demande attestation - Envoi d'un document de l...   \n",
       "22                                       Réclamations   \n",
       "\n",
       "                              date  \\\n",
       "33  mardi 5 juin 2018 16 h 06 CEST   \n",
       "21                02/06/2018 11:07   \n",
       "10                30/05/2018 10:12   \n",
       "15  lundi 4 juin 2018 10 h 22 CEST   \n",
       "22                03/06/2018 16:52   \n",
       "\n",
       "                                               from  \\\n",
       "33  Monsieur Dupont <monsieurdupont@extensionb.com>   \n",
       "21                    monsieurdupont@extensionf.net   \n",
       "10           Dupont <monsieurdupont@extensiona.com>   \n",
       "15  Monsieur Dupont <monsieurdupont@extensionc.com>   \n",
       "22                    monsieurdupont@extensiona.com   \n",
       "\n",
       "                                                  to   attachment sexe  age  \\\n",
       "33                     demandes@societeimaginaire.fr  [\"doc.pdf\"]    M   45   \n",
       "21  Societe Imaginaire <region@Societeimaginaire.fr>           []    M   64   \n",
       "10                   conseiller@Societeimaginaire.fr           []    F   63   \n",
       "15                     demandes@societeimaginaire.fr           []    F   88   \n",
       "22                   conseiller@Societeimaginaire.fr           []    F   20   \n",
       "\n",
       "          label  is_begin_by_transfer  is_answer  is_transfer  \\\n",
       "33   habitation                 False      False        False   \n",
       "21     vehicule                  True      False         True   \n",
       "10        bilan                  True       True        False   \n",
       "15  resiliation                 False      False        False   \n",
       "22   habitation                  True      False        False   \n",
       "\n",
       "                                  structured_historic  \\\n",
       "33  [{'text': ' \\n  \\n  \\n  \\n  \\n  \\n Madame, Mon...   \n",
       "21  [{'text': ' \\n  \\n  \\n  \\n Bonjour, \\n  \\n Pou...   \n",
       "10  [{'text': \" \\n  \\n  \\n  \\n Bonjour Monsieur, \\...   \n",
       "15  [{'text': \" \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n...   \n",
       "22  [{'text': \" \\n  \\n  \\n  \\n Numéro Tél. : 06000...   \n",
       "\n",
       "                                      structured_body  \\\n",
       "33  [{'meta': {'date': None, 'from': None, 'to': N...   \n",
       "21  [{'meta': {'date': None, 'from': None, 'to': N...   \n",
       "10  [{'meta': {'date': None, 'from': None, 'to': N...   \n",
       "15  [{'meta': {'date': None, 'from': None, 'to': N...   \n",
       "22  [{'meta': {'date': None, 'from': None, 'to': N...   \n",
       "\n",
       "                                            last_body  \\\n",
       "33     Je vous prie de trouver ci-joint une déclar...   \n",
       "21   Pourriez vous faire suite au mail suivant en ...   \n",
       "10  Pouvez-vous m'appeler lundi prochain en fin d'...   \n",
       "15   Je vous remercie pour l'attestation demandée ...   \n",
       "22     Numéro Tél. : 0600000000 E-mail : monsieurd...   \n",
       "\n",
       "                                           clean_body  \\\n",
       "33  je vous prie de trouver ci-joint une declarati...   \n",
       "21  pourriez vous faire suite au mail suivant en d...   \n",
       "10  pouvez-vous m'appeler lundi prochain en fin d'...   \n",
       "15  je vous remercie pour l'attestation demandee p...   \n",
       "22  numero tel. : 0600000000 e-mail : monsieurdupo...   \n",
       "\n",
       "                                         clean_header  \\\n",
       "33      declarations de sinistre corporel et materiel   \n",
       "21                             changement de vehicule   \n",
       "10                                            demande   \n",
       "15  demande attestation envoi d'un document de la ...   \n",
       "22                                       reclamations   \n",
       "\n",
       "                                               tokens  semantic_score  \n",
       "33  [prie, trouver, ci-joint, declaration, sinistr...        0.126272  \n",
       "21  [pourriez, faire, suite, mail, suivant, date, ...        0.122522  \n",
       "10  [pouvez-vous, appeler, flag_date_, prochain, f...        0.122522  \n",
       "15  [remercie, attestation, demandee, telephone, r...        0.102057  \n",
       "22  [numero, tel, flag_phone_, e-mail, flag_mail_,...        0.100749  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose the name of the column returned (default is \"score\")\n",
    "return_column = \"semantic_score\"\n",
    "\n",
    "# Predict the sentiment score on each email of the DataFrame\n",
    "df_emails_clean = semantic_detector.predict(df_emails_clean, return_column=return_column)\n",
    "\n",
    "# Print emails with the maximum sentiment score\n",
    "df_emails_clean.sort_values(by=return_column, ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The SentimentDetector class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SemanticDetector class provides an unsupervised methodology to assign a sentiment score to a corpus of documents/emails. The methodology used to predict a sentiment score using the SemanticDetector is described below:\n",
    "\n",
    "1. **Define a list of seed words that caracterize a sentiment**\n",
    "    - Take a list of seed words as input\n",
    "    - If the `extend_seed_word_list` parameter is set to True: extend the list of seed words with words sharing the same root (dance -> [\"dancing\", \"dancer\"])  \n",
    "    \n",
    "    \n",
    "2. **Fit the model (= create a lexicon to assign a score for every word in the vocabulary)**\n",
    "    - Create a lexicon for each seed word by computing the cosine similarity between the seed word and all the words in the vocabulary is computed.\n",
    "    - Aggregate the similarity score obtained for the different seed words in a unique lexicon\n",
    "    - (To compute cosine similarities, a trained embedding is required.)  \n",
    "    \n",
    "3. **Predict a sentiment score for emails/documents**\n",
    "    - Filter out the tokens in the document that are not in the vocabulary.\n",
    "    - For each remaining token, compute its sentiment score using the lexicon.\n",
    "    - For each email, aggregate the score accross different tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arguments of a SemanticDetector object are :\n",
    "    \n",
    "- **base_seed_words :** the list of seed words that caracterize a sentiment/theme\n",
    "- **base_anti_seed_words :** the list of seed words that caracterize undesired sentiments/themes\n",
    "- **anti_weight :** the weight of anti_seeds in the computation of the semantic score\n",
    "- **tokens_column :** name of the column in the input DataFrame that contains tokens\n",
    "- **extend_seed_word_list :** if True: complement seed words with words sharing the same root (dance -> [\"dancing\", \"dancer\"]). Default value False.\n",
    "- **normalize_scores :** if True: normalize the lexicon scores of eache word. Default value False.\n",
    "- **aggregation_function_seed_wise :** Function to aggregate the scores associated with a token accross the different seeds. Default function is a max.\n",
    "- **aggregation_function_email_wise :** Function to aggregate the scores associated with the different tokens in an email. Default function is the 60th percentile.\n",
    "- **n_jobs :** the number of cores used for computation. Default value, 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out undesired themes with using \"anti seed words\" and \"anti_ratio\"\n",
    "\n",
    "If you want to detect emergency in your emails, you could use the seed word `\"emergency\"`.  \n",
    "* \"I need an answer, this is an emergency !!\" => Semantic score = 0.98   \n",
    "\n",
    "But you might detect undesired sentences such as:\n",
    "* \"Yesterday I tested the emergency brake of my car\" => Semantic score = 0.95  \n",
    "\n",
    "You can prevent the detection of undesired themes using anti seed words:  \n",
    "* `base_anti_seed_word_list = ['brake']`\n",
    "* \"Yesterday I tested the emergency brake of my car\" => Semantic score = 0.50  \n",
    "\n",
    "You can control the contribution of anti seed words using the `anti_weight` (default 0.3):  \n",
    "* `base_anti_seed_word_list = ['brake']`\n",
    "* `anti_weight = 0.6`\n",
    "* \"Yesterday I tested the emergency brake of my car\" => Semantic score = 0.30  \n",
    "\n",
    "The formula used to compute the semantic score is:  \n",
    "* semantic score = seed_word_contrib - anti_weight * anti_seed_word_contrib  \n",
    "\n",
    "Warning : an `anti_weight` above one means anti seeds contribute more (negatively) than regular seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:50:13.777212Z",
     "start_time": "2021-05-27T13:50:13.746323Z"
    }
   },
   "outputs": [],
   "source": [
    "seed_word_list = ['immatriculation']\n",
    "anti_seed_word_list = ['demandes']\n",
    "\n",
    "\n",
    "# Instanciate SentimentDetector objects\n",
    "regular_semantic_detector = SemanticDetector(base_seed_words=seed_word_list, tokens_column='tokens')\n",
    "semantic_detector_with_anti = SemanticDetector(base_seed_words=seed_word_list, tokens_column='tokens', \n",
    "                                               base_anti_seed_words = anti_seed_word_list)\n",
    "semantic_detector_with_anti2 = SemanticDetector(base_seed_words=seed_word_list, tokens_column='tokens', \n",
    "                                               base_anti_seed_words = anti_seed_word_list, anti_weight=0.5)\n",
    "\n",
    "\n",
    "# Fit the SentimentDetectors using the trained embedding\n",
    "regular_semantic_detector.fit(embedding=embedding)\n",
    "semantic_detector_with_anti.fit(embedding=embedding)\n",
    "semantic_detector_with_anti2.fit(embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:50:13.822235Z",
     "start_time": "2021-05-27T13:50:13.781559Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>header</th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>attachment</th>\n",
       "      <th>sexe</th>\n",
       "      <th>age</th>\n",
       "      <th>label</th>\n",
       "      <th>is_begin_by_transfer</th>\n",
       "      <th>...</th>\n",
       "      <th>is_transfer</th>\n",
       "      <th>structured_historic</th>\n",
       "      <th>structured_body</th>\n",
       "      <th>last_body</th>\n",
       "      <th>clean_body</th>\n",
       "      <th>clean_header</th>\n",
       "      <th>tokens</th>\n",
       "      <th>semantic_score</th>\n",
       "      <th>semantic_score with anti (anti_weight=0.3)</th>\n",
       "      <th>semantic_score with anti (anti_weight=0.5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>\\n  \\n  \\n  \\n  \\n  \\n Madame, Monsieur, \\n  ...</td>\n",
       "      <td>déclarations de sinistre corporel et matériel</td>\n",
       "      <td>mardi 5 juin 2018 16 h 06 CEST</td>\n",
       "      <td>Monsieur Dupont &lt;monsieurdupont@extensionb.com&gt;</td>\n",
       "      <td>demandes@societeimaginaire.fr</td>\n",
       "      <td>[\"doc.pdf\"]</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>habitation</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': ' \\n  \\n  \\n  \\n  \\n  \\n Madame, Mon...</td>\n",
       "      <td>[{'meta': {'date': None, 'from': None, 'to': N...</td>\n",
       "      <td>Je vous prie de trouver ci-joint une déclar...</td>\n",
       "      <td>je vous prie de trouver ci-joint une declarati...</td>\n",
       "      <td>declarations de sinistre corporel et materiel</td>\n",
       "      <td>[prie, trouver, ci-joint, declaration, sinistr...</td>\n",
       "      <td>0.126272</td>\n",
       "      <td>0.143268</td>\n",
       "      <td>0.142439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\\n  \\n  \\n  \\n Bonjour, \\n  \\n Pourriez vous ...</td>\n",
       "      <td>Fwd: Changement de vehicule</td>\n",
       "      <td>02/06/2018 11:07</td>\n",
       "      <td>monsieurdupont@extensionf.net</td>\n",
       "      <td>Societe Imaginaire &lt;region@Societeimaginaire.fr&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>M</td>\n",
       "      <td>64</td>\n",
       "      <td>vehicule</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>[{'text': ' \\n  \\n  \\n  \\n Bonjour, \\n  \\n Pou...</td>\n",
       "      <td>[{'meta': {'date': None, 'from': None, 'to': N...</td>\n",
       "      <td>Pourriez vous faire suite au mail suivant en ...</td>\n",
       "      <td>pourriez vous faire suite au mail suivant en d...</td>\n",
       "      <td>changement de vehicule</td>\n",
       "      <td>[pourriez, faire, suite, mail, suivant, date, ...</td>\n",
       "      <td>0.122522</td>\n",
       "      <td>0.131613</td>\n",
       "      <td>0.137674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\\n  \\n  \\n  \\n Bonjour Monsieur, \\n Pouvez-vo...</td>\n",
       "      <td>Re: Demande</td>\n",
       "      <td>30/05/2018 10:12</td>\n",
       "      <td>Dupont &lt;monsieurdupont@extensiona.com&gt;</td>\n",
       "      <td>conseiller@Societeimaginaire.fr</td>\n",
       "      <td>[]</td>\n",
       "      <td>F</td>\n",
       "      <td>63</td>\n",
       "      <td>bilan</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': \" \\n  \\n  \\n  \\n Bonjour Monsieur, \\...</td>\n",
       "      <td>[{'meta': {'date': None, 'from': None, 'to': N...</td>\n",
       "      <td>Pouvez-vous m'appeler lundi prochain en fin d'...</td>\n",
       "      <td>pouvez-vous m'appeler lundi prochain en fin d'...</td>\n",
       "      <td>demande</td>\n",
       "      <td>[pouvez-vous, appeler, flag_date_, prochain, f...</td>\n",
       "      <td>0.122522</td>\n",
       "      <td>0.131613</td>\n",
       "      <td>0.137674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n Bonjour Ma...</td>\n",
       "      <td>demande attestation - Envoi d'un document de l...</td>\n",
       "      <td>lundi 4 juin 2018 10 h 22 CEST</td>\n",
       "      <td>Monsieur Dupont &lt;monsieurdupont@extensionc.com&gt;</td>\n",
       "      <td>demandes@societeimaginaire.fr</td>\n",
       "      <td>[]</td>\n",
       "      <td>F</td>\n",
       "      <td>88</td>\n",
       "      <td>resiliation</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': \" \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n...</td>\n",
       "      <td>[{'meta': {'date': None, 'from': None, 'to': N...</td>\n",
       "      <td>Je vous remercie pour l'attestation demandée ...</td>\n",
       "      <td>je vous remercie pour l'attestation demandee p...</td>\n",
       "      <td>demande attestation envoi d'un document de la ...</td>\n",
       "      <td>[remercie, attestation, demandee, telephone, r...</td>\n",
       "      <td>0.102057</td>\n",
       "      <td>0.099603</td>\n",
       "      <td>0.089742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\\n  \\n  \\n  \\n Numéro Tél. : 0600000000 \\n E-...</td>\n",
       "      <td>Réclamations</td>\n",
       "      <td>03/06/2018 16:52</td>\n",
       "      <td>monsieurdupont@extensiona.com</td>\n",
       "      <td>conseiller@Societeimaginaire.fr</td>\n",
       "      <td>[]</td>\n",
       "      <td>F</td>\n",
       "      <td>20</td>\n",
       "      <td>habitation</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': \" \\n  \\n  \\n  \\n Numéro Tél. : 06000...</td>\n",
       "      <td>[{'meta': {'date': None, 'from': None, 'to': N...</td>\n",
       "      <td>Numéro Tél. : 0600000000 E-mail : monsieurd...</td>\n",
       "      <td>numero tel. : 0600000000 e-mail : monsieurdupo...</td>\n",
       "      <td>reclamations</td>\n",
       "      <td>[numero, tel, flag_phone_, e-mail, flag_mail_,...</td>\n",
       "      <td>0.100749</td>\n",
       "      <td>0.095212</td>\n",
       "      <td>0.089878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 body  \\\n",
       "33   \\n  \\n  \\n  \\n  \\n  \\n Madame, Monsieur, \\n  ...   \n",
       "21   \\n  \\n  \\n  \\n Bonjour, \\n  \\n Pourriez vous ...   \n",
       "10   \\n  \\n  \\n  \\n Bonjour Monsieur, \\n Pouvez-vo...   \n",
       "15   \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n Bonjour Ma...   \n",
       "22   \\n  \\n  \\n  \\n Numéro Tél. : 0600000000 \\n E-...   \n",
       "\n",
       "                                               header  \\\n",
       "33      déclarations de sinistre corporel et matériel   \n",
       "21                        Fwd: Changement de vehicule   \n",
       "10                                        Re: Demande   \n",
       "15  demande attestation - Envoi d'un document de l...   \n",
       "22                                       Réclamations   \n",
       "\n",
       "                              date  \\\n",
       "33  mardi 5 juin 2018 16 h 06 CEST   \n",
       "21                02/06/2018 11:07   \n",
       "10                30/05/2018 10:12   \n",
       "15  lundi 4 juin 2018 10 h 22 CEST   \n",
       "22                03/06/2018 16:52   \n",
       "\n",
       "                                               from  \\\n",
       "33  Monsieur Dupont <monsieurdupont@extensionb.com>   \n",
       "21                    monsieurdupont@extensionf.net   \n",
       "10           Dupont <monsieurdupont@extensiona.com>   \n",
       "15  Monsieur Dupont <monsieurdupont@extensionc.com>   \n",
       "22                    monsieurdupont@extensiona.com   \n",
       "\n",
       "                                                  to   attachment sexe  age  \\\n",
       "33                     demandes@societeimaginaire.fr  [\"doc.pdf\"]    M   45   \n",
       "21  Societe Imaginaire <region@Societeimaginaire.fr>           []    M   64   \n",
       "10                   conseiller@Societeimaginaire.fr           []    F   63   \n",
       "15                     demandes@societeimaginaire.fr           []    F   88   \n",
       "22                   conseiller@Societeimaginaire.fr           []    F   20   \n",
       "\n",
       "          label  is_begin_by_transfer  ...  is_transfer  \\\n",
       "33   habitation                 False  ...        False   \n",
       "21     vehicule                  True  ...         True   \n",
       "10        bilan                  True  ...        False   \n",
       "15  resiliation                 False  ...        False   \n",
       "22   habitation                  True  ...        False   \n",
       "\n",
       "                                  structured_historic  \\\n",
       "33  [{'text': ' \\n  \\n  \\n  \\n  \\n  \\n Madame, Mon...   \n",
       "21  [{'text': ' \\n  \\n  \\n  \\n Bonjour, \\n  \\n Pou...   \n",
       "10  [{'text': \" \\n  \\n  \\n  \\n Bonjour Monsieur, \\...   \n",
       "15  [{'text': \" \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n...   \n",
       "22  [{'text': \" \\n  \\n  \\n  \\n Numéro Tél. : 06000...   \n",
       "\n",
       "                                      structured_body  \\\n",
       "33  [{'meta': {'date': None, 'from': None, 'to': N...   \n",
       "21  [{'meta': {'date': None, 'from': None, 'to': N...   \n",
       "10  [{'meta': {'date': None, 'from': None, 'to': N...   \n",
       "15  [{'meta': {'date': None, 'from': None, 'to': N...   \n",
       "22  [{'meta': {'date': None, 'from': None, 'to': N...   \n",
       "\n",
       "                                            last_body  \\\n",
       "33     Je vous prie de trouver ci-joint une déclar...   \n",
       "21   Pourriez vous faire suite au mail suivant en ...   \n",
       "10  Pouvez-vous m'appeler lundi prochain en fin d'...   \n",
       "15   Je vous remercie pour l'attestation demandée ...   \n",
       "22     Numéro Tél. : 0600000000 E-mail : monsieurd...   \n",
       "\n",
       "                                           clean_body  \\\n",
       "33  je vous prie de trouver ci-joint une declarati...   \n",
       "21  pourriez vous faire suite au mail suivant en d...   \n",
       "10  pouvez-vous m'appeler lundi prochain en fin d'...   \n",
       "15  je vous remercie pour l'attestation demandee p...   \n",
       "22  numero tel. : 0600000000 e-mail : monsieurdupo...   \n",
       "\n",
       "                                         clean_header  \\\n",
       "33      declarations de sinistre corporel et materiel   \n",
       "21                             changement de vehicule   \n",
       "10                                            demande   \n",
       "15  demande attestation envoi d'un document de la ...   \n",
       "22                                       reclamations   \n",
       "\n",
       "                                               tokens semantic_score  \\\n",
       "33  [prie, trouver, ci-joint, declaration, sinistr...       0.126272   \n",
       "21  [pourriez, faire, suite, mail, suivant, date, ...       0.122522   \n",
       "10  [pouvez-vous, appeler, flag_date_, prochain, f...       0.122522   \n",
       "15  [remercie, attestation, demandee, telephone, r...       0.102057   \n",
       "22  [numero, tel, flag_phone_, e-mail, flag_mail_,...       0.100749   \n",
       "\n",
       "    semantic_score with anti (anti_weight=0.3)  \\\n",
       "33                                    0.143268   \n",
       "21                                    0.131613   \n",
       "10                                    0.131613   \n",
       "15                                    0.099603   \n",
       "22                                    0.095212   \n",
       "\n",
       "    semantic_score with anti (anti_weight=0.5)  \n",
       "33                                    0.142439  \n",
       "21                                    0.137674  \n",
       "10                                    0.137674  \n",
       "15                                    0.089742  \n",
       "22                                    0.089878  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose the name of the column returned (default is \"score\")\n",
    "return_column1 = \"semantic_score\"\n",
    "return_column2 = \"semantic_score with anti (anti_weight=0.3)\"\n",
    "return_column3 = \"semantic_score with anti (anti_weight=0.5)\"\n",
    "\n",
    "\n",
    "\n",
    "# Predict the sentiment score on each email of the DataFrame\n",
    "df_emails_clean = regular_semantic_detector.predict(df_emails_clean, return_column=return_column1)\n",
    "df_emails_clean = semantic_detector_with_anti.predict(df_emails_clean, return_column=return_column2)\n",
    "df_emails_clean = semantic_detector_with_anti2.predict(df_emails_clean, return_column=return_column3)\n",
    "\n",
    "\n",
    "# Print emails with the maximum sentiment score\n",
    "df_emails_clean.sort_values(by=return_column1, ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find extra seed words with the `extend_seed_word_list` parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SentimentDetector \"extend_seed_word_list\" parameter activates the search for extra seed words sharing the same root as the base seed words.  \n",
    "\n",
    "For example, if \"dance\" is a base seed word, \"extend_seed_word_list\" will loop through the words in the embedding vocabulary and find new seed words such as \"dancer\", \"dancing\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:50:13.841197Z",
     "start_time": "2021-05-27T13:50:13.826022Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instanciate a SentimentDetector object\n",
    "semantic_detector_extended_seed = SemanticDetector(\n",
    "    base_seed_words=['tel', 'assur'], tokens_column='tokens', extend_seed_word_list=True)\n",
    "\n",
    "# Fit the SentimentDetector using the trained embedding\n",
    "semantic_detector_extended_seed.fit(embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:50:13.850939Z",
     "start_time": "2021-05-27T13:50:13.843177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tel': ['telephonique', 'telephone', 'tel'], 'assur': ['assurance', 'assurer']}\n",
      "['telephonique', 'telephone', 'tel', 'assurance', 'assurer']\n"
     ]
    }
   ],
   "source": [
    "# Print the extended list of seed words\n",
    "print(semantic_detector_extended_seed.seed_dict)\n",
    "print(semantic_detector_extended_seed.seed_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a custom function to aggregate lexicon scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate token score over seeds\n",
    "The SemanticDetector computes a similarity between a word and every seed words.  \n",
    "An aggretion function is then used to keep a single score for each token.  \n",
    "\n",
    "Exemple : \n",
    "- Seed word list : [\"horse\", \"animal\"]\n",
    "- Embedding : simulated\n",
    "\n",
    "Lexicon \"horse\" :\n",
    "{\n",
    "  \"apple\" : 0.2,\n",
    "  ...\n",
    "  \"hello\" : 0.1,\n",
    "  ...\n",
    "  \"ponies\" : 8.8,\n",
    "  ...\n",
    "  \"zebra\" : 1.2\n",
    "}  \n",
    "Lexicon \"animal\" :\n",
    "{\n",
    "  \"apple\" : 0.1,\n",
    "  ...\n",
    "  \"hello\" : 0.3,\n",
    "  ...\n",
    "  \"ponies\" : 4.8,\n",
    "  ...\n",
    "  \"zebra\" : 6.2\n",
    "}\n",
    "\n",
    "**Aggregated Lexicon :**  \n",
    "{\n",
    "  \"apple\" : 0.2,\n",
    "  ...\n",
    "  \"hello\" : 0.3,\n",
    "  ...\n",
    "  \"ponies\" : 8.8,\n",
    "  ...\n",
    "  \"zebra\" : 6.2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate semantic score over tokens\n",
    "When evaluating an email, each word in the email has an associated score.  \n",
    "An aggregation function is used to keep a single score for each email.  \n",
    "\n",
    "Exemple : \n",
    "- Sentence : \"Hello, I like ponies\"\n",
    "- Seed word list : [\"horse\", \"animal\"]\n",
    "- Embedding : simulated\n",
    "\n",
    "**Sentence score :**  \n",
    "- score : score(Hello) + score(I) + score(like) + score(ponies)\n",
    "- score : 0.3 + 0.1 + 0.2 + 8.8 = 9.4\n",
    "\n",
    "\n",
    "The semantic score for the email is thus 9.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default aggregation functions\n",
    "\n",
    "The default aggregation methodology is the following:  \n",
    "- Seed-wise aggregation : For a token, take the max score accross seed\n",
    "  - Exemple :  \n",
    "    ponies_score = 8.8 (lexicon \"horse\")   \n",
    "    ponies_score = 4.8 (lexicon \"animal\")  \n",
    "    => Score for the \"ponies\" token = np.max(8.8, 4.8) = 8.8  \n",
    "  \n",
    "  \n",
    "- Email-wise aggregation : Given a list of token scores, take the percentile 60 as the sentiment_score for the email\n",
    "  - Exemple :  \n",
    "    token_score_list : [0.3 (hello), 0.3 (i), 0.2 (ponies)]  \n",
    "    => sentiment_score = np.percentile([0.3, 0.3, 0.2, 8.8], 60) = 0.3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:50:13.877539Z",
     "start_time": "2021-05-27T13:50:13.857577Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instanciate a SentimentDetector object with custom aggregation function:\n",
    "# - A mean for the seed-wise aggregation\n",
    "# - A 95th percentile for the email-wise aggregation\n",
    "\n",
    "def aggregation_mean(x):\n",
    "    return np.mean(x, axis=0)\n",
    "\n",
    "def aggregation_percentile_95(x):\n",
    "    return np.percentile(x, 95)\n",
    "\n",
    "semantic_detector_custom_aggregation = SemanticDetector(\n",
    "    base_seed_words=['client'], \n",
    "    tokens_column='tokens', \n",
    "    aggregation_function_seed_wise=aggregation_mean,\n",
    "    aggregation_function_email_wise=aggregation_percentile_95\n",
    ")\n",
    "\n",
    "# Fit the SentimentDetector using the trained embedding\n",
    "semantic_detector_custom_aggregation.fit(embedding=embedding)\n",
    "\n",
    "# Predict the sentiment score on each email of the DataFrame\n",
    "df_emails_clean_custom_aggregation = semantic_detector_custom_aggregation.predict(df_emails_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:50:15.163028Z",
     "start_time": "2021-05-27T13:50:13.879358Z"
    }
   },
   "outputs": [],
   "source": [
    "semantic_detector_multiprocessing = SemanticDetector(\n",
    "    base_seed_words=['certificat'], \n",
    "    tokens_column='tokens', \n",
    "    n_jobs = 2\n",
    ")\n",
    "\n",
    "# Fit the SentimentDetector using the trained embedding\n",
    "semantic_detector_multiprocessing.fit(embedding=embedding)\n",
    "\n",
    "# Predict the sentiment score on each email of the DataFrame\n",
    "df_emails_multiprocessing = semantic_detector_multiprocessing.predict(df_emails_clean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "melusine_perso38",
   "language": "python",
   "name": "melusine_perso38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
