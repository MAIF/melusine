{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models subpackage tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NeuralModel class is a generic class used to manage neural networks implemented with Keras. It offers methods to save, load, train and use for classification the neural networks.\n",
    "\n",
    "Melusine provides two built-in Keras model : cnn_model and rnn_model based on the models used in-house at Maif. However the user is free to implement neural networks tailored for its needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NeuralModel class can take as input either :\n",
    "- a text input : a cleaned text, usually the cleaned body or the concatenation of the cleaned body and the cleaned header.\n",
    "- a text input and a metadata input : the metadata input has to be dummified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "from melusine.data.data_loader import load_email_data\n",
    "df_emails_full = load_email_data(type=\"full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new clean_text column is the concatenation of the clean_header column and the clean_body column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emails_full['clean_text'] = df_emails_full['clean_header'] + \" \" + df_emails_full['clean_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'devis habitation je suis client chez vous pouvez vous m etablir un devis pour mon fils qui souhaite louer lappartement suivant : 25 rue du rueimaginaire 77000'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emails_full.clean_text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metadata input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the metadata used are :\n",
    "- the extension : gmail, outlook, wanadoo..\n",
    "- the day of the week at which the email has been sent\n",
    "- the hour at which the email has been sent\n",
    "- the minute at which the email has been sent\n",
    "- the attachment types : pdf, png .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_emails_full.drop(\"label\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y is a numpy array containing the encoded labels :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "y = df_emails_full['label']\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 10,  3,  0,  0,  4,  7, 10,  1, 10,  2,  5, 10, 10,  4,  7,  7,\n",
       "       10,  0,  9,  4, 10,  4,  7, 10, 10,  6,  7,  3,  8, 10, 10, 10,  4,\n",
       "        7,  3,  5,  4,  4, 10])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The NeuralModel class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from melusine.models.train import NeuralModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NeuralModel class is a generic class used to manage neural networks implemented with Keras. It offers methods to save, load, train and use for classification the neural networks.\n",
    "\n",
    "Its arguments are :\n",
    "- **architecture_function :** a function returning a Model instance from Keras.\n",
    "- **pretrained_embedding :** the pretrained embedding matrix as an numpy array.\n",
    "- **text_input_column :** the name of the column that will provide the text input, by default clean_text.\n",
    "- **meta_input_list :** the list of the names of the columns containing the metadata. If empty list or None the model is used without metadata. Default value, ['extension', 'dayofweek', 'hour', 'min'].\n",
    "- **vocab_size :** the size of vocabulary for neurol network model. Default value, 25000.\n",
    "- **seq_size :** the maximum size of input for neural model. Default value, 100.\n",
    "- **loss :** the loss function for training. Default value, 'categorical_crossentropy'.\n",
    "- **batch_size :** the size of batches for the training of the neural network model. Default value, 4096.\n",
    "- **n_epochs :** the number of epochs for the training of the neural network model. Default value, 15."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### architecture_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from melusine.models.neural_architectures import cnn_model, rnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**architecture_function** is a function returning a Model instance from Keras.\n",
    "Melusine provides two built-in neural networks : **cnn_model** and **rnn_model** based on the models used in-house at Maif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pretrained_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding have to be trained on the user's dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from melusine.nlp_tools.embedding import Word2VecTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the trainer\n",
    "embedding_trainer = Word2VecTrainer(\n",
    "    input_column='clean_body',\n",
    "    workers=4,\n",
    "    min_count=3\n",
    ")\n",
    "\n",
    "# Train the word embeddings model\n",
    "embedding_trainer.train(df_emails_full)\n",
    "\n",
    "pretrained_embedding = embedding_trainer.embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuralModel used with text and metadata input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This neural network model will use the **clean_text** column for the text input and the dummified **extension**, **dayofweek**, **hour** and **min** as metadata input :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = NeuralModel(architecture_function=cnn_model,\n",
    "                       pretrained_embedding=pretrained_embedding,\n",
    "                       text_input_column=\"clean_text\",\n",
    "                       meta_input_list=['extension','attachment_type', 'dayofweek', 'hour', 'min'],\n",
    "                       n_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the training, logs are saved in \"train\" situated in the data directory. Use tensorboard to follow training using \n",
    "- \"tensorboard --logdir data\" from your terminal  \n",
    "- directly from a notebook with \"%load_ext tensorboard\" and \"%tensorboard --logdir data\" magics command (see https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-17 14:50:00.997749: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-17 14:50:01.276949: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-09-17 14:50:01.276970: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-09-17 14:50:01.278224: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-09-17 14:50:01.376352: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.4535 - accuracy: 0.0250\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 2.3362 - accuracy: 0.2500\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.2837 - accuracy: 0.3250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-17 14:50:03.137627: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-09-17 14:50:03.137643: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-09-17 14:50:03.191653: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-09-17 14:50:03.211686: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-09-17 14:50:03.238816: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./data/train/plugins/profile/2021_09_17_14_50_03\n",
      "\n",
      "2021-09-17 14:50:03.243165: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to ./data/train/plugins/profile/2021_09_17_14_50_03/MacBookPro-hperrier-C02W308DHV27.trace.json.gz\n",
      "2021-09-17 14:50:03.268601: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./data/train/plugins/profile/2021_09_17_14_50_03\n",
      "\n",
      "2021-09-17 14:50:03.269237: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to ./data/train/plugins/profile/2021_09_17_14_50_03/MacBookPro-hperrier-C02W308DHV27.memory_profile.json.gz\n",
      "2021-09-17 14:50:03.272411: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./data/train/plugins/profile/2021_09_17_14_50_03\n",
      "Dumped tool data for xplane.pb to ./data/train/plugins/profile/2021_09_17_14_50_03/MacBookPro-hperrier-C02W308DHV27.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./data/train/plugins/profile/2021_09_17_14_50_03/MacBookPro-hperrier-C02W308DHV27.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./data/train/plugins/profile/2021_09_17_14_50_03/MacBookPro-hperrier-C02W308DHV27.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./data/train/plugins/profile/2021_09_17_14_50_03/MacBookPro-hperrier-C02W308DHV27.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./data/train/plugins/profile/2021_09_17_14_50_03/MacBookPro-hperrier-C02W308DHV27.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.2461 - accuracy: 0.3250\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.1257 - accuracy: 0.3500\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.1148 - accuracy: 0.3750\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.0318 - accuracy: 0.3000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.0287 - accuracy: 0.3500\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.9907 - accuracy: 0.3250\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.9660 - accuracy: 0.2500\n"
     ]
    }
   ],
   "source": [
    "nn_model.fit(X,y,tensorboard_log_dir=\"./data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](../docs/_static/tensorboard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **save_nn_model** method saves :\n",
    "- the Keras model as a json file \n",
    "- the weights as a h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.save_nn_model(\"./data/nn_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the **save_nn_model** used the NeuralModel object can be saved as a pickle file :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "_ = joblib.dump(nn_model,\"./data/nn_model.pickle\",compress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NeuralModel saved as a pickle file has to be loaded first : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = joblib.load(\"./data/nn_model.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the Keras model and its weights can be loaded :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.load_nn_model(\"./data/nn_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res = nn_model.predict(X)\n",
    "y_res = le.inverse_transform(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuralModel used with only text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_emails_full[['clean_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = NeuralModel(architecture_function=cnn_model,\n",
    "                       pretrained_embedding=pretrained_embedding,\n",
    "                       text_input_column=\"clean_text\",\n",
    "                       meta_input_list=None,\n",
    "                       n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 2.4096 - accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.3548 - accuracy: 0.1500\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.3079 - accuracy: 0.2250\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.2478 - accuracy: 0.2000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1785 - accuracy: 0.2250\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.0874 - accuracy: 0.2750\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.0661 - accuracy: 0.3250\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.0266 - accuracy: 0.3500\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.0438 - accuracy: 0.3250\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.9104 - accuracy: 0.3000\n"
     ]
    }
   ],
   "source": [
    "nn_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hperrier/PycharmProjects/melusine_perso/melusine/models/train.py:376: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.TOKENS_COL] = X[self.text_input_column].apply(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res = nn_model.predict(X)\n",
    "y_res = le.inverse_transform(y_res)\n",
    "y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "melusine_perso38",
   "language": "python",
   "name": "melusine_perso38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
