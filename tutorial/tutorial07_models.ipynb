{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models subpackage tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NeuralModel class is a generic class used to manage neural networks implemented with Keras. It offers methods to save, load, train and use for classification the neural networks.\n",
    "\n",
    "Melusine provides two built-in Keras model : cnn_model and rnn_model based on the models used in-house at Maif. However the user is free to implement neural networks tailored for its needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NeuralModel class can take as input either :\n",
    "- a text input : a cleaned text, usually the cleaned body or the concatenation of the cleaned body and the cleaned header.\n",
    "- a text input and a metadata input : the metadata input has to be dummified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_emails_preprocessed = pd.read_csv('./data/emails_preprocessed.csv', encoding='utf-8', sep=';')\n",
    "df_emails_preprocessed['clean_header'] = df_emails_preprocessed['clean_header'].astype(str)\n",
    "df_emails_preprocessed['clean_body'] = df_emails_preprocessed['clean_body'].astype(str)\n",
    "df_emails_preprocessed['attachment'] = df_emails_preprocessed['attachment'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['body', 'header', 'date', 'from', 'to', 'attachment', 'sexe', 'age',\n",
       "       'label', 'is_begin_by_transfer', 'is_answer', 'is_transfer',\n",
       "       'structured_historic', 'structured_body', 'last_body', 'clean_body',\n",
       "       'clean_header', 'tokens'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emails_preprocessed.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new clean_text column is the concatenation of the clean_header column and the clean_body column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emails_preprocessed['clean_text'] = df_emails_preprocessed['clean_header'] + \" \" + df_emails_preprocessed['clean_body']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'devis habitation je suis client chez vous pouvez vous m etablir un devis pour mon fils qui souhaite louer lappartement suivant : 25 rue du rueimaginaire  flag_cp_ '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emails_preprocessed.clean_text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metadata input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the metadata used are :\n",
    "- the extension : gmail, outlook, wanadoo..\n",
    "- the day of the week at which the email has been sent\n",
    "- the hour at which the email has been sent\n",
    "- the minute at which the email has been sent\n",
    "- the attachment types : pdf, png .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv('./data/metadata.csv', encoding='utf-8', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['extension__0', 'extension__1', 'extension__2', 'extension__3',\n",
       "       'extension__4', 'extension__5', 'extension__6', 'extension__7',\n",
       "       'extension__8', 'dayofweek__0', 'dayofweek__1', 'dayofweek__3',\n",
       "       'dayofweek__4', 'hour__6', 'hour__8', 'hour__9', 'hour__10', 'hour__11',\n",
       "       'hour__12', 'hour__14', 'hour__15', 'hour__16', 'hour__17', 'hour__18',\n",
       "       'hour__20', 'hour__22', 'min__0', 'min__2', 'min__4', 'min__6',\n",
       "       'min__9', 'min__10', 'min__11', 'min__12', 'min__15', 'min__16',\n",
       "       'min__19', 'min__20', 'min__21', 'min__22', 'min__24', 'min__28',\n",
       "       'min__29', 'min__30', 'min__32', 'min__33', 'min__37', 'min__38',\n",
       "       'min__39', 'min__40', 'min__44', 'min__45', 'min__49', 'min__54',\n",
       "       'min__56', 'min__58', 'attachment_type__0', 'attachment_type__1',\n",
       "       'attachment_type__2', 'attachment_type__3', 'attachment_type__4',\n",
       "       'attachment_type__5', 'attachment_type__6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extension__0</th>\n",
       "      <th>extension__1</th>\n",
       "      <th>extension__2</th>\n",
       "      <th>extension__3</th>\n",
       "      <th>extension__4</th>\n",
       "      <th>extension__5</th>\n",
       "      <th>extension__6</th>\n",
       "      <th>extension__7</th>\n",
       "      <th>extension__8</th>\n",
       "      <th>dayofweek__0</th>\n",
       "      <th>...</th>\n",
       "      <th>min__54</th>\n",
       "      <th>min__56</th>\n",
       "      <th>min__58</th>\n",
       "      <th>attachment_type__0</th>\n",
       "      <th>attachment_type__1</th>\n",
       "      <th>attachment_type__2</th>\n",
       "      <th>attachment_type__3</th>\n",
       "      <th>attachment_type__4</th>\n",
       "      <th>attachment_type__5</th>\n",
       "      <th>attachment_type__6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   extension__0  extension__1  extension__2  extension__3  extension__4  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             1             0             0             0             0   \n",
       "3             0             0             0             1             0   \n",
       "4             1             0             0             0             0   \n",
       "\n",
       "   extension__5  extension__6  extension__7  extension__8  dayofweek__0  ...  \\\n",
       "0             0             0             0             1             0  ...   \n",
       "1             0             0             0             1             0  ...   \n",
       "2             0             0             0             0             0  ...   \n",
       "3             0             0             0             0             0  ...   \n",
       "4             0             0             0             0             0  ...   \n",
       "\n",
       "   min__54  min__56  min__58  attachment_type__0  attachment_type__1  \\\n",
       "0        0        0        0                   0                   0   \n",
       "1        0        0        0                   0                   0   \n",
       "2        0        0        0                   0                   0   \n",
       "3        0        0        0                   0                   0   \n",
       "4        0        0        0                   0                   0   \n",
       "\n",
       "   attachment_type__2  attachment_type__3  attachment_type__4  \\\n",
       "0                   0                   0                   1   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   1   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   attachment_type__5  attachment_type__6  \n",
       "0                   0                   0  \n",
       "1                   1                   0  \n",
       "2                   0                   0  \n",
       "3                   0                   1  \n",
       "4                   1                   0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining X and y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X is a Pandas dataframe with a clean_text column that will be used for the text input and columns containing the dummified metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([df_emails_preprocessed['clean_text'],df_meta],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y is a numpy array containing the encoded labels :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "y = df_emails_preprocessed['label']\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 10,  3,  0,  0,  4,  7, 10,  1, 10,  2,  5, 10, 10,  4,  7,  7,\n",
       "       10,  0,  9,  4, 10,  4,  7, 10, 10,  6,  7,  3,  8, 10, 10, 10,  4,\n",
       "        7,  3,  5,  4,  4, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The NeuralModel class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from melusine.models.train import NeuralModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NeuralModel class is a generic class used to manage neural networks implemented with Keras. It offers methods to save, load, train and use for classification the neural networks.\n",
    "\n",
    "Its arguments are :\n",
    "- **architecture_function :** a function returning a Model instance from Keras.\n",
    "- **pretrained_embedding :** the pretrained embedding matrix as an numpy array.\n",
    "- **text_input_column :** the name of the column that will provide the text input, by default clean_text.\n",
    "- **meta_input_list :** the list of the names of the columns containing the metadata. If empty list or None the model is used without metadata. Default value, ['extension', 'dayofweek', 'hour', 'min'].\n",
    "- **vocab_size :** the size of vocabulary for neurol network model. Default value, 25000.\n",
    "- **seq_size :** the maximum size of input for neural model. Default value, 100.\n",
    "- **loss :** the loss function for training. Default value, 'categorical_crossentropy'.\n",
    "- **batch_size :** the size of batches for the training of the neural network model. Default value, 4096.\n",
    "- **n_epochs :** the number of epochs for the training of the neural network model. Default value, 15."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### architecture_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from melusine.models.neural_architectures import cnn_model, rnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**architecture_function** is a function returning a Model instance from Keras.\n",
    "Melusine provides two built-in neural networks : **cnn_model** and **rnn_model** based on the models used in-house at Maif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pretrained_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding have to be trained on the user's dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from melusine.nlp_tools.embedding import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/97133d/.conda/envs/emails_prod_without_melusine/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "pretrained_embedding = Embedding().load('./data/embedding.pickle') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuralModel used with text and metadata input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This neural network model will use the **clean_text** column for the text input and the dummified **extension**, **dayofweek**, **hour** and **min** as metadata input :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = NeuralModel(architecture_function=cnn_model,\n",
    "                       pretrained_embedding=pretrained_embedding,\n",
    "                       text_input_column=\"clean_text\",\n",
    "                       meta_input_list=['extension','attachment_type', 'dayofweek', 'hour', 'min'],\n",
    "                       n_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the training, logs are saved in \"train\" situated in the data directory. Use tensorboard to follow training using \n",
    "- \"tensorboard --logdir data\" from your terminal  \n",
    "- directly from a notebook with \"%load_ext tensorboard\" and \"%tensorboard --logdir data\" magics command (see https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.3633 - accuracy: 0.2000\n",
      "Epoch 2/10\n",
      "WARNING:tensorflow:From /home/97133d/.conda/envs/emails_prod_without_melusine/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3123 - accuracy: 0.3000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1948 - accuracy: 0.3250\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0985 - accuracy: 0.3000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9438 - accuracy: 0.3750\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9953 - accuracy: 0.3750\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9191 - accuracy: 0.3500\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9413 - accuracy: 0.2750\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9103 - accuracy: 0.2250\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8107 - accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "nn_model.fit(X,y,tensorboard_log_dir=\"./data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](../docs/_static/tensorboard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **save_nn_model** method saves :\n",
    "- the Keras model as a json file \n",
    "- the weights as a h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.save_nn_model(\"./data/nn_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the **save_nn_model** used the NeuralModel object can be saved as a pickle file :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "_ = joblib.dump(nn_model,\"./data/nn_model.pickle\",compress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NeuralModel saved as a pickle file has to be loaded first : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = joblib.load(\"./data/nn_model.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the Keras model and its weights can be loaded :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.load_nn_model(\"./data/nn_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res = nn_model.predict(X)\n",
    "y_res = le.inverse_transform(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuralModel used with only text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_emails_preprocessed[['clean_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = NeuralModel(architecture_function=cnn_model,\n",
    "                       pretrained_embedding=pretrained_embedding,\n",
    "                       text_input_column=\"clean_text\",\n",
    "                       meta_input_list=None,\n",
    "                       n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../melusine/melusine/nlp_tools/tokenizer.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"tokens\"] = apply_func(X, self.tokenize)\n",
      "../../melusine/melusine/nlp_tools/tokenizer.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"tokens\"] = apply_func(X, lambda x: x[\"tokens\"][0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3980 - accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3485 - accuracy: 0.3250\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2431 - accuracy: 0.3500\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.1012 - accuracy: 0.2500\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9597 - accuracy: 0.3000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1738 - accuracy: 0.2500\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.9769 - accuracy: 0.3500\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8084 - accuracy: 0.3750\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.9164 - accuracy: 0.3500\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.8704 - accuracy: 0.3250\n"
     ]
    }
   ],
   "source": [
    "nn_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res = nn_model.predict(X)\n",
    "y_res = le.inverse_transform(y_res)\n",
    "y_res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emails_prod_without_melusine",
   "language": "python",
   "name": "emails_prod_without_melusine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
